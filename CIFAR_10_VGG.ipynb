{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2751b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,   200] loss: 2.192\n",
      "[1,   400] loss: 2.028\n",
      "[1,   600] loss: 1.918\n",
      "[2,   200] loss: 1.855\n",
      "[2,   400] loss: 1.827\n",
      "[2,   600] loss: 1.787\n",
      "[3,   200] loss: 1.686\n",
      "[3,   400] loss: 1.637\n",
      "[3,   600] loss: 1.600\n",
      "[4,   200] loss: 1.516\n",
      "[4,   400] loss: 1.481\n",
      "[4,   600] loss: 1.446\n",
      "[5,   200] loss: 1.371\n",
      "[5,   400] loss: 1.360\n",
      "[5,   600] loss: 1.303\n",
      "[6,   200] loss: 1.260\n",
      "[6,   400] loss: 1.242\n",
      "[6,   600] loss: 1.219\n",
      "[7,   200] loss: 1.158\n",
      "[7,   400] loss: 1.140\n",
      "[7,   600] loss: 1.127\n",
      "[8,   200] loss: 1.087\n",
      "[8,   400] loss: 1.062\n",
      "[8,   600] loss: 1.033\n",
      "[9,   200] loss: 0.998\n",
      "[9,   400] loss: 1.007\n",
      "[9,   600] loss: 0.972\n",
      "[10,   200] loss: 0.940\n",
      "[10,   400] loss: 0.928\n",
      "[10,   600] loss: 0.925\n",
      "[11,   200] loss: 0.908\n",
      "[11,   400] loss: 0.888\n",
      "[11,   600] loss: 0.871\n",
      "[12,   200] loss: 0.842\n",
      "[12,   400] loss: 0.829\n",
      "[12,   600] loss: 0.837\n",
      "[13,   200] loss: 0.809\n",
      "[13,   400] loss: 0.788\n",
      "[13,   600] loss: 0.789\n",
      "[14,   200] loss: 0.768\n",
      "[14,   400] loss: 0.770\n",
      "[14,   600] loss: 0.758\n",
      "[15,   200] loss: 0.743\n",
      "[15,   400] loss: 0.726\n",
      "[15,   600] loss: 0.725\n",
      "[16,   200] loss: 0.696\n",
      "[16,   400] loss: 0.712\n",
      "[16,   600] loss: 0.702\n",
      "[17,   200] loss: 0.667\n",
      "[17,   400] loss: 0.666\n",
      "[17,   600] loss: 0.675\n",
      "[18,   200] loss: 0.644\n",
      "[18,   400] loss: 0.659\n",
      "[18,   600] loss: 0.657\n",
      "[19,   200] loss: 0.637\n",
      "[19,   400] loss: 0.638\n",
      "[19,   600] loss: 0.628\n",
      "[20,   200] loss: 0.601\n",
      "[20,   400] loss: 0.610\n",
      "[20,   600] loss: 0.607\n",
      "[21,   200] loss: 0.603\n",
      "[21,   400] loss: 0.597\n",
      "[21,   600] loss: 0.580\n",
      "[22,   200] loss: 0.584\n",
      "[22,   400] loss: 0.568\n",
      "[22,   600] loss: 0.572\n",
      "[23,   200] loss: 0.552\n",
      "[23,   400] loss: 0.551\n",
      "[23,   600] loss: 0.564\n",
      "[24,   200] loss: 0.556\n",
      "[24,   400] loss: 0.545\n",
      "[24,   600] loss: 0.542\n",
      "[25,   200] loss: 0.522\n",
      "[25,   400] loss: 0.517\n",
      "[25,   600] loss: 0.522\n",
      "[26,   200] loss: 0.504\n",
      "[26,   400] loss: 0.509\n",
      "[26,   600] loss: 0.524\n",
      "[27,   200] loss: 0.505\n",
      "[27,   400] loss: 0.511\n",
      "[27,   600] loss: 0.499\n",
      "[28,   200] loss: 0.488\n",
      "[28,   400] loss: 0.499\n",
      "[28,   600] loss: 0.506\n",
      "[29,   200] loss: 0.473\n",
      "[29,   400] loss: 0.494\n",
      "[29,   600] loss: 0.493\n",
      "[30,   200] loss: 0.462\n",
      "[30,   400] loss: 0.463\n",
      "[30,   600] loss: 0.476\n",
      "[31,   200] loss: 0.470\n",
      "[31,   400] loss: 0.465\n",
      "[31,   600] loss: 0.463\n",
      "[32,   200] loss: 0.456\n",
      "[32,   400] loss: 0.450\n",
      "[32,   600] loss: 0.442\n",
      "[33,   200] loss: 0.439\n",
      "[33,   400] loss: 0.453\n",
      "[33,   600] loss: 0.442\n",
      "[34,   200] loss: 0.418\n",
      "[34,   400] loss: 0.455\n",
      "[34,   600] loss: 0.441\n",
      "[35,   200] loss: 0.424\n",
      "[35,   400] loss: 0.416\n",
      "[35,   600] loss: 0.419\n",
      "[36,   200] loss: 0.407\n",
      "[36,   400] loss: 0.423\n",
      "[36,   600] loss: 0.410\n",
      "[37,   200] loss: 0.401\n",
      "[37,   400] loss: 0.428\n",
      "[37,   600] loss: 0.403\n",
      "[38,   200] loss: 0.403\n",
      "[38,   400] loss: 0.405\n",
      "[38,   600] loss: 0.404\n",
      "[39,   200] loss: 0.391\n",
      "[39,   400] loss: 0.400\n",
      "[39,   600] loss: 0.394\n",
      "[40,   200] loss: 0.399\n",
      "[40,   400] loss: 0.379\n",
      "[40,   600] loss: 0.388\n",
      "[41,   200] loss: 0.381\n",
      "[41,   400] loss: 0.382\n",
      "[41,   600] loss: 0.393\n",
      "[42,   200] loss: 0.422\n",
      "[42,   400] loss: 0.375\n",
      "[42,   600] loss: 0.393\n",
      "[43,   200] loss: 0.360\n",
      "[43,   400] loss: 0.379\n",
      "[43,   600] loss: 0.353\n",
      "[44,   200] loss: 0.371\n",
      "[44,   400] loss: 0.353\n",
      "[44,   600] loss: 0.359\n",
      "[45,   200] loss: 0.347\n",
      "[45,   400] loss: 0.382\n",
      "[45,   600] loss: 0.360\n",
      "[46,   200] loss: 0.332\n",
      "[46,   400] loss: 0.353\n",
      "[46,   600] loss: 0.356\n",
      "[47,   200] loss: 0.369\n",
      "[47,   400] loss: 0.366\n",
      "[47,   600] loss: 0.347\n",
      "[48,   200] loss: 0.367\n",
      "[48,   400] loss: 0.331\n",
      "[48,   600] loss: 0.346\n",
      "[49,   200] loss: 0.410\n",
      "[49,   400] loss: 0.369\n",
      "[49,   600] loss: 0.346\n",
      "[50,   200] loss: 0.335\n",
      "[50,   400] loss: 0.337\n",
      "[50,   600] loss: 0.334\n",
      "[51,   200] loss: 0.331\n",
      "[51,   400] loss: 0.327\n",
      "[51,   600] loss: 0.325\n",
      "[52,   200] loss: 0.322\n",
      "[52,   400] loss: 0.320\n",
      "[52,   600] loss: 0.327\n",
      "[53,   200] loss: 0.329\n",
      "[53,   400] loss: 0.325\n",
      "[53,   600] loss: 0.324\n",
      "[54,   200] loss: 0.311\n",
      "[54,   400] loss: 0.319\n",
      "[54,   600] loss: 0.317\n",
      "[55,   200] loss: 0.317\n",
      "[55,   400] loss: 0.305\n",
      "[55,   600] loss: 0.321\n",
      "[56,   200] loss: 0.308\n",
      "[56,   400] loss: 0.317\n",
      "[56,   600] loss: 0.317\n",
      "[57,   200] loss: 0.293\n",
      "[57,   400] loss: 0.295\n",
      "[57,   600] loss: 0.305\n",
      "[58,   200] loss: 0.297\n",
      "[58,   400] loss: 0.310\n",
      "[58,   600] loss: 0.293\n",
      "[59,   200] loss: 0.308\n",
      "[59,   400] loss: 0.290\n",
      "[59,   600] loss: 0.297\n",
      "[60,   200] loss: 0.290\n",
      "[60,   400] loss: 0.291\n",
      "[60,   600] loss: 0.302\n",
      "[61,   200] loss: 0.291\n",
      "[61,   400] loss: 0.303\n",
      "[61,   600] loss: 0.297\n",
      "[62,   200] loss: 0.285\n",
      "[62,   400] loss: 0.303\n",
      "[62,   600] loss: 0.284\n",
      "[63,   200] loss: 0.290\n",
      "[63,   400] loss: 0.347\n",
      "[63,   600] loss: 0.301\n",
      "[64,   200] loss: 0.274\n",
      "[64,   400] loss: 0.297\n",
      "[64,   600] loss: 0.287\n",
      "[65,   200] loss: 0.271\n",
      "[65,   400] loss: 0.283\n",
      "[65,   600] loss: 0.304\n",
      "[66,   200] loss: 0.275\n",
      "[66,   400] loss: 0.281\n",
      "[66,   600] loss: 0.267\n",
      "[67,   200] loss: 0.275\n",
      "[67,   400] loss: 0.278\n",
      "[67,   600] loss: 0.265\n",
      "[68,   200] loss: 0.275\n",
      "[68,   400] loss: 0.276\n",
      "[68,   600] loss: 0.258\n",
      "[69,   200] loss: 0.265\n",
      "[69,   400] loss: 0.266\n",
      "[69,   600] loss: 0.347\n",
      "[70,   200] loss: 0.294\n",
      "[70,   400] loss: 0.290\n",
      "[70,   600] loss: 0.273\n",
      "[71,   200] loss: 0.256\n",
      "[71,   400] loss: 0.262\n",
      "[71,   600] loss: 0.270\n",
      "[72,   200] loss: 0.241\n",
      "[72,   400] loss: 0.265\n",
      "[72,   600] loss: 0.258\n",
      "[73,   200] loss: 0.246\n",
      "[73,   400] loss: 0.244\n",
      "[73,   600] loss: 0.266\n",
      "[74,   200] loss: 0.253\n",
      "[74,   400] loss: 0.261\n",
      "[74,   600] loss: 0.301\n",
      "[75,   200] loss: 0.253\n",
      "[75,   400] loss: 0.246\n",
      "[75,   600] loss: 0.257\n",
      "[76,   200] loss: 0.284\n",
      "[76,   400] loss: 0.253\n",
      "[76,   600] loss: 0.260\n",
      "[77,   200] loss: 0.242\n",
      "[77,   400] loss: 0.255\n",
      "[77,   600] loss: 0.236\n",
      "[78,   200] loss: 0.413\n",
      "[78,   400] loss: 0.293\n",
      "[78,   600] loss: 0.279\n",
      "[79,   200] loss: 0.249\n",
      "[79,   400] loss: 0.231\n",
      "[79,   600] loss: 0.250\n",
      "[80,   200] loss: 0.234\n",
      "[80,   400] loss: 0.248\n",
      "[80,   600] loss: 0.237\n",
      "[81,   200] loss: 0.234\n",
      "[81,   400] loss: 0.237\n",
      "[81,   600] loss: 0.237\n",
      "[82,   200] loss: 0.234\n",
      "[82,   400] loss: 0.241\n",
      "[82,   600] loss: 0.316\n",
      "[83,   200] loss: 0.267\n",
      "[83,   400] loss: 0.242\n",
      "[83,   600] loss: 0.226\n",
      "[84,   200] loss: 0.236\n",
      "[84,   400] loss: 0.238\n",
      "[84,   600] loss: 0.226\n",
      "[85,   200] loss: 0.226\n",
      "[85,   400] loss: 0.229\n",
      "[85,   600] loss: 0.226\n",
      "[86,   200] loss: 0.250\n",
      "[86,   400] loss: 0.318\n",
      "[86,   600] loss: 0.252\n",
      "[87,   200] loss: 0.225\n",
      "[87,   400] loss: 0.219\n",
      "[87,   600] loss: 0.225\n",
      "[88,   200] loss: 0.228\n",
      "[88,   400] loss: 0.215\n",
      "[88,   600] loss: 0.254\n",
      "[89,   200] loss: 0.229\n",
      "[89,   400] loss: 0.217\n",
      "[89,   600] loss: 0.304\n",
      "[90,   200] loss: 0.226\n",
      "[90,   400] loss: 0.226\n",
      "[90,   600] loss: 0.217\n",
      "[91,   200] loss: 0.233\n",
      "[91,   400] loss: 0.214\n",
      "[91,   600] loss: 0.223\n",
      "[92,   200] loss: 0.207\n",
      "[92,   400] loss: 0.219\n",
      "[92,   600] loss: 0.225\n",
      "[93,   200] loss: 0.219\n",
      "[93,   400] loss: 0.213\n",
      "[93,   600] loss: 0.218\n",
      "[94,   200] loss: 0.202\n",
      "[94,   400] loss: 0.219\n",
      "[94,   600] loss: 0.223\n",
      "[95,   200] loss: 0.224\n",
      "[95,   400] loss: 0.221\n",
      "[95,   600] loss: 0.222\n",
      "[96,   200] loss: 0.206\n",
      "[96,   400] loss: 0.225\n",
      "[96,   600] loss: 0.222\n",
      "[97,   200] loss: 0.215\n",
      "[97,   400] loss: 0.211\n",
      "[97,   600] loss: 0.215\n",
      "[98,   200] loss: 0.225\n",
      "[98,   400] loss: 0.207\n",
      "[98,   600] loss: 0.227\n",
      "[99,   200] loss: 0.201\n",
      "[99,   400] loss: 0.218\n",
      "[99,   600] loss: 0.224\n",
      "[100,   200] loss: 0.231\n",
      "[100,   400] loss: 0.211\n",
      "[100,   600] loss: 0.252\n",
      "[101,   200] loss: 0.217\n",
      "[101,   400] loss: 0.214\n",
      "[101,   600] loss: 0.199\n",
      "[102,   200] loss: 0.194\n",
      "[102,   400] loss: 0.205\n",
      "[102,   600] loss: 0.214\n",
      "[103,   200] loss: 0.211\n",
      "[103,   400] loss: 0.205\n",
      "[103,   600] loss: 0.201\n",
      "[104,   200] loss: 0.198\n",
      "[104,   400] loss: 0.206\n",
      "[104,   600] loss: 0.211\n",
      "[105,   200] loss: 0.218\n",
      "[105,   400] loss: 0.192\n",
      "[105,   600] loss: 0.201\n",
      "[106,   200] loss: 0.206\n",
      "[106,   400] loss: 0.201\n",
      "[106,   600] loss: 0.210\n",
      "[107,   200] loss: 0.212\n",
      "[107,   400] loss: 0.195\n",
      "[107,   600] loss: 0.482\n",
      "[108,   200] loss: 0.233\n",
      "[108,   400] loss: 0.225\n",
      "[108,   600] loss: 0.219\n",
      "[109,   200] loss: 0.190\n",
      "[109,   400] loss: 0.197\n",
      "[109,   600] loss: 0.187\n",
      "[110,   200] loss: 0.185\n",
      "[110,   400] loss: 0.182\n",
      "[110,   600] loss: 0.188\n",
      "[111,   200] loss: 0.180\n",
      "[111,   400] loss: 0.194\n",
      "[111,   600] loss: 0.186\n",
      "[112,   200] loss: 0.201\n",
      "[112,   400] loss: 0.332\n",
      "[112,   600] loss: 0.227\n",
      "[113,   200] loss: 0.202\n",
      "[113,   400] loss: 0.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113,   600] loss: 0.199\n",
      "[114,   200] loss: 0.188\n",
      "[114,   400] loss: 0.209\n",
      "[114,   600] loss: 0.186\n",
      "[115,   200] loss: 0.180\n",
      "[115,   400] loss: 0.187\n",
      "[115,   600] loss: 0.184\n",
      "[116,   200] loss: 0.190\n",
      "[116,   400] loss: 0.215\n",
      "[116,   600] loss: 0.204\n",
      "[117,   200] loss: 0.226\n",
      "[117,   400] loss: 0.219\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_655973/3135936075.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2854\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2856\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2794\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2796\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2739\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2741\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2742\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2705\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the VGG model architecture for CIFAR-10 with added Dropout\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),  # Add Dropout here and in other layers\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define data transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the VGG model, loss function, and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)  # Use Adam optimizer\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(200):  # Adjust the number of epochs as needed\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluation\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097a80a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
